---
title: "ML model comparison"
output: html_notebook
---

```{r}
rm(list=ls())
library(tidyverse)
library(reshape2)
library(rstan)
library(latex2exp)
library(caret)
library(gbm)
options(mc.cores=4)
rstan_options(auto_write = TRUE)
source("monitornew.R")
source("r_star_monitor.R")
```

# AR1 model
```{r}
f_ar1 <- function(rho, sigma, L){
  x <- vector(length = L)
  x[1] <- rnorm(1, 0, sd=sigma)
  for(i in 2:L)
    x[i] = rho * x[i - 1] + rnorm(1, 0, sd=sigma)
  return(x)
}

# Generates three chains with same var; one with a different var
f_generate_lower_var_four <- function(var_ratio, rho, sigma, L){
  x <- matrix(nrow = L, ncol = 4)
  for(i in 1:3)
    x[, i] <- f_ar1(rho, sigma, L)
  z <- f_ar1(rho, sigma * sqrt(var_ratio), L)
  x[, 4] <- z
  return(x)
}

r_star_ml_variety <- function(x, split_chains=T, training_percent=0.7, method_="gbm", caretGrid=NULL){
  
  if(split_chains)
    x <- split_data(x)
  
  nparams <- dim(x)[3]
  nchains <- dim(x)[2]
  niter <- dim(x)[1]
  m_flattened <- matrix(nrow = nrow(x) * nchains,
                        ncol = (nparams + 1))
  k <- 1
  for(i in 1:nchains){
    for(j in 1:nrow(x)){
      m_flattened[k, 1:nparams] <- x[j, i, ]
      m_flattened[k, (nparams + 1)] <- i
      k <- k + 1
    }
  }
  m_flattened <- m_flattened %>% 
    as.data.frame()
  colnames(m_flattened)[nparams + 1] <- "chain"
  r <- m_flattened %>% 
    mutate(chain=as.factor(chain))
  # if only 1 param, add in a column of random noise since gbm requires >1 dims
  if(nparams==1)
    r <- r %>% 
      mutate(V_new=rnorm(nrow(r)))
  
  rand_samples <- sample(1:nrow(r), training_percent * nrow(r))
  training_data <- r[rand_samples, ]
  testing_data <- r[-rand_samples, ]
  
  if(!is.null(caretGrid))
    gbmFit <- train(chain ~ ., data = training_data, 
                   trControl = trainControl(method = 'none'),
                   method=method_,
                   tuneGrid = caretGrid)
  else
    gbmFit <- train(chain ~ ., data = training_data, 
                   trControl = trainControl(method = 'none'),
                   method=method_)
  plda <- predict(object=gbmFit, newdata=testing_data)
  a_accuracy <- 
    tibble(predicted=plda, actual=testing_data$chain) %>%
    mutate(correct=if_else(predicted==actual, 1, 0)) %>% 
    summarise(mean(correct)) %>% 
    pull()
  return(a_accuracy * n_distinct(training_data$chain))
}

f_replicate_ml_variety <- function(x, method_, caretGrid_=NULL){
  temp <- x
  a_array <- array(dim=c(2000, 4, 1))
  a_array[,,1] <- temp
  a_accuracy <- r_star_ml_variety(a_array, method_=method_, caretGrid = caretGrid_)
  return(a_accuracy)
}

f_replicate_rhat <- function(x){
  temp <- x
  a_array <- array(dim=c(2000, 4, 1))
  a_array[,,1] <- temp
  mon <- monitor_extra(split_data(a_array))
  a_accuracy <- mon$zfsRhat
  return(a_accuracy)
}

f_replicate_ml_variety_gridded <- function(x, method_="gbm", caretGrids_){
  n_things <- nrow(caretGrids_)
  v_accuracy <- length(n_things)
  for(i in 1:n_things){
    caretGrid <- caretGrids_[i, ]
    v_accuracy[i] <- f_replicate_ml_variety(x, method_, caretGrid)
  }
  return(list(a_accuracy=max(v_accuracy), hyper=caretGrids_[which.max(v_accuracy),]))
}

tunegrid_rf <- tibble(mtry = 1:2)
tunegrid_gbm <- expand.grid(interaction.depth=c(3), 
                             n.trees = 50,
                             shrinkage=c(0.1),
                             n.minobsinnode=10)
tunegrid_knn <- tibble(k = c(5, 10, 15, 20, 40))
tunegrid_svm <- tibble(C = c(0.25, 0.5, 0.75))
tunegrid_nnet <- tibble(size=c(2, 3, 4, 5), decay=c(0.5, 0.5, 0.5, 0.5))
niterates <- 50
m_res <- matrix(nrow=niterates, ncol = 6)
l_rf_hyper <- vector(length = niterates, mode="list")
l_knn_hyper <- vector(length = niterates, mode="list")
l_svm_hyper <- vector(length = niterates, mode="list")
l_nnet_hyper <- vector(length = niterates, mode="list")
for(i in 1:niterates){
  print(i)
  x <- f_generate_lower_var_four(1/3, 0.3, 1, 2000)
  m_res[i, 1] <- f_replicate_ml_variety(x, "gbm", tunegrid_gbm)
  m_res[i, 2] <- f_replicate_rhat(x)
  temp <- f_replicate_ml_variety_gridded(x, method_="rf", caretGrids_ = tunegrid_rf)
  l_rf_hyper[[i]] <- temp$hyper
  m_res[i, 3] <- temp$a_accuracy
  temp <- f_replicate_ml_variety_gridded(x, "knn", tunegrid_knn)
  l_knn_hyper[[i]] <- temp$hyper
  m_res[i, 4] <- temp$a_accuracy
  temp <- f_replicate_ml_variety_gridded(x, "svmLinear", tunegrid_svm)
  l_svm_hyper[[i]] <- temp$hyper
  m_res[i, 5] <- temp$a_accuracy
  temp <- f_replicate_ml_variety_gridded(x, "nnet", tunegrid_nnet)
  l_nnet_hyper[[i]] <- temp$hyper
  m_res[i, 6] <- temp$a_accuracy
}

colnames(m_res) <- c("gbm", "rhat", "rf", "knn", "svm", "nnet")
m_res1 <- m_res %>%
  as.data.frame() %>% 
  mutate(iter=seq_along(gbm))
saveRDS(m_res1, "../data/ml_comparison.rds")
m_res1 <- readRDS("../data/ml_comparison.rds")
g <- m_res1 %>% 
  dplyr::select(-one_of("rhat")) %>% 
  melt(id.vars="iter") %>% 
  ggplot(aes(x=fct_reorder(as.factor(variable), value), y=value)) +
  geom_boxplot() +
  xlab("ML model") +
  ylab("R*") +
  theme(text=element_text(colour="black", size=14))
ggsave("../output/ml_comparison_ar1.pdf", g, width = 12, height = 8)
```

# Eight schools model
```{r}
source("eight_schools.data.R")
eight_schools <- list(J=J, y=y, sigma=sigma)
model_cp <- stan_model("eight_schools_cp.stan")
model_ncp <- stan_model("eight_schools_ncp.stan")

fit_cp <- sampling(
  model_cp, data = eight_schools,
  iter = 4000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)

fit_ncp <- sampling(
  model_ncp, data = eight_schools,
  iter = 4000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)

x_cp <- rstan::extract(fit_cp, permuted=F)
x_ncp <- rstan::extract(fit_ncp, permuted=F)
```

Try out different ML models
```{r}
f_replicate_ml_simple <- function(x, method_, caretGrid_=NULL){
  a_array <- x
  a_accuracy <- r_star_ml_variety(a_array, method_=method_, caretGrid = caretGrid_)
  return(a_accuracy)
}

f_replicate_rhat_simple <- function(x){
  a_array <- x
  mon <- monitor_extra(split_data(a_array))
  a_accuracy <- mon$zfsRhat
  return(a_accuracy)
}

f_replicate_ml_simple_gridded <- function(x, method_="gbm", caretGrids_){
  n_things <- nrow(caretGrids_)
  v_accuracy <- length(n_things)
  for(i in 1:n_things){
    caretGrid <- caretGrids_[i, ]
    v_accuracy[i] <- f_replicate_ml_simple(x, method_, caretGrid)
  }
  return(list(a_accuracy=max(v_accuracy), hyper=caretGrids_[which.max(v_accuracy),]))
}

m_res <- matrix(nrow=2, ncol = 6)
l_rf_hyper <- vector(length = 2, mode="list")
l_knn_hyper <- vector(length = 2, mode="list")
l_svm_hyper <- vector(length = 2, mode="list")
l_nnet_hyper <- vector(length = 2, mode="list")
x <- x_cp
i <- 1
m_res[i, 1] <- f_replicate_ml_simple(x, "gbm", tunegrid_gbm)
m_res[i, 2] <- max(f_replicate_rhat_simple(x))
temp <- f_replicate_ml_simple_gridded(x, method_="rf", caretGrids_ = tunegrid_rf)
l_rf_hyper[[i]] <- temp$hyper
m_res[i, 3] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "knn", tunegrid_knn)
l_knn_hyper[[i]] <- temp$hyper
m_res[i, 4] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "svmLinear", tunegrid_svm)
l_svm_hyper[[i]] <- temp$hyper
m_res[i, 5] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "nnet", tunegrid_nnet)
l_nnet_hyper[[i]] <- temp$hyper
m_res[i, 6] <- temp$a_accuracy
x <- x_ncp
i <- 2
m_res[i, 1] <- f_replicate_ml_simple(x, "gbm", tunegrid_gbm)
m_res[i, 2] <- max(f_replicate_rhat_simple(x))
temp <- f_replicate_ml_simple_gridded(x, method_="rf", caretGrids_ = tunegrid_rf)
l_rf_hyper[[i]] <- temp$hyper
m_res[i, 3] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "knn", tunegrid_knn)
l_knn_hyper[[i]] <- temp$hyper
m_res[i, 4] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "svmLinear", tunegrid_svm)
l_svm_hyper[[i]] <- temp$hyper
m_res[i, 5] <- temp$a_accuracy
temp <- f_replicate_ml_simple_gridded(x, "nnet", tunegrid_nnet)
l_nnet_hyper[[i]] <- temp$hyper
m_res[i, 6] <- temp$a_accuracy

colnames(m_res) <- c("gbm", "rhat", "rf", "knn", "svm", "nnet")
m_res <- m_res %>%
  as.data.frame() %>% 
  mutate(model=c("cp", "ncp"))
# saveRDS(m_res, "../data/ml_comparison_8_schools.rds")
m_res %>% 
  dplyr::select(-rhat) %>% 
  melt(id.vars="model") %>% 
  ggplot(aes(x=fct_reorder(as.factor(variable), value), y=value, colour=as.factor(model))) +
  geom_point(size=4) +
  xlab("ML model") +
  scale_color_brewer("8 schools model", palette = "Dark2") +
  ylab("R*") +
  theme(text=element_text(colour="black", size=14))
# ggsave("../output/ml_comparison_8_schools.pdf", width = 12, height = 8)

x_ncp[,,11] %>%
  as.data.frame() %>%
  mutate(iter=seq(1,2000,1)) %>%
  melt(id.vars="iter") %>%
  ggplot(aes(x=value, fill=as.factor(variable))) +
  stat_density(position="identity", alpha=0.2)
```

