\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2018

% ready for submission
% \usepackage{neurips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{bbm}


\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
\newcommand{\Dir}[0]{\textrm{Dirichlet}}
\newcommand{\Ray}[0]{\textrm{Rayleigh}}
\newcommand{\gam}[0]{\textrm{Gamma}}
\newcommand{\dgamma}[0]{\textrm{Gamma}}
\newcommand{\dpoisson}[0]{\textrm{Poisson}}
\newcommand{\dbeta}[0]{\textrm{Beta}}
\newcommand{\dbern}[0]{\textrm{Bernoulli}}
\newcommand{\dunif}[0]{\mathrm{Uniform}}
\newcommand{\dgig}[0]{\textrm{GIG}}
\newcommand{\dnormal}[0]{\mathrm{Normal}}
\newcommand{\dt}[0]{\mathrm{t}}
\newcommand{\igamma}[0]{\textrm{Gamma}^{-1}}
\newcommand{\rayl}[0]{\textrm{Rayleigh}}
\newcommand{\Exp}[0]{\textrm{Exponential}}
\newcommand{\Bet}[0]{\textrm{Beta}}
\newcommand{\GEM}[0]{\textrm{GEM}}
\newcommand{\DP}[0]{\textrm{DP}}
\newcommand{\ESS}[0]{\mathrm{ESS}}
\newcommand{\bm}[1]{\boldsymbol{#1}}
\newcommand{\bbeta}{\bm{\beta}}
\newcommand{\bpi}{\bm{\pi}}
\newcommand{\bomega}{\bm{\omega}}
\newcommand{\bgamma}{\bm{\gamma}}
\newcommand{\blambda}{\bm{\lambda}}
\newcommand{\bphi}{\bm{\phi}}
\newcommand{\btheta}{\bm{\theta}}
\newcommand{\bmu}{\bm{\mu}}
\newcommand{\bb}{\bm{b}}
\newcommand{\bk}{\bm{k}}
\newcommand{\bl}{\bm{l}}
\newcommand{\bn}{\bm{n}}
\newcommand{\bw}{\bm{w}}
\newcommand{\bz}{\bm{z}}
\newcommand{\bx}{\bm{x}}
\newcommand{\bX}{\bm{X}}
\newcommand{\by}{\bm{y}}
\newcommand{\bZ}{\bm{Z}}
\newcommand{\bW}{\bm{W}}
\newcommand{\bS}{\bm{S}}
\newcommand{\bH}{\bm{H}}
\newcommand{\Mult}{\textrm{Multinomial}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\NEW}{\textrm{\tiny new}}
\newcommand{\OLD}{\textrm{\tiny old}}
\newcommand{\sigmat}{\sigma^2}
\newcommand{\IBP}{\textrm{IBP}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\Eq}{\mathbb{E}_q}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cHq}{\mathcal{H}_q}
\newcommand{\test}[1]{\mbox{$#1$}^{\small \mbox{test}}}
\newcommand{\alphaW}{\alpha^{(W)}}
\newcommand{\alphaH}{\alpha^{(H)}}
\newcommand{\betaW}{\beta^{(W)}}
\newcommand{\betaH}{\beta^{(H)}}
\newcommand{\gammaW}{\gamma^{(W)}}
\newcommand{\gammaH}{\gamma^{(H)}}
\newcommand{\gammaT}{\gamma^{(\theta)}}
\newcommand{\rhoW}{\rho^{(W)}}
\newcommand{\rhoH}{\rho^{(H)}}
\newcommand{\rhoT}{\rho^{(\theta)}}
\newcommand{\tauW}{\tau^{(W)}}
\newcommand{\tauH}{\tau^{(H)}}
\newcommand{\tauT}{\tau^{(\theta)}}
\newcommand{\muW}{\hat{W}}
\newcommand{\muH}{\hat{H}}
\newcommand{\Var}{\textrm{Var}}
\newcommand{\LF}{\mathrm{Leapfrog}}

\title{$R^*$: A robust MCMC convergence diagnostic with uncertainty via gradient-boosted machines}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
	 Ben Lambert\\
	 MRC Centre for Global Infectious Disease Analysis\\
	 School of Public Health\\
	 Imperial College London\\
	 W2 1PG, United Kingdom\\
	 \texttt{ben.c.lambert@gmail.com} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
	Markov chain Monte Carlo (MCMC) has transformed Bayesian model inference over the past three decades: mainly because of this, Bayesian inference is now a workhorse of applied scientists. Despite its importance, MCMC is a notoriously subtle beast. Indeed, the words of statisticians often echo that MCMC ``should be used with caution, almost as a last resort''; the problem is that we are usually at the ``last resort'' for interesting models. Central to these concerns is the difficulty in determining whether Markov chains have converged to the posterior distribution. Under general conditions, MCMC sampling converges asymptotically to the posterior distribution, but this provides no guarantees about its finite sample performance. The predominant method for monitoring convergence is to run multiple chains and monitor individual chains' characteristics and compare these to the population as a whole: if within-chain and between-chain summaries are comparable, then this may indicate that the chains have converged to a stationary distribution. Qualitatively, these summary statistics aim to determine whether it is possible to predict the chain that generated a particular sample: if these predictions are accurate, then the chains have not mixed and convergence has not occurred. Here, we introduce a new method for probing convergence based on training machine learning algorithms to classify samples according to the chain that generated them: we call our convergence measure $R^*$. In contrast to the predominant $\hat{R}$, $R^*$ is a single statistic across all parameters that captures whether convergence has occurred, although individual variables' importance for this metric can also be determined. Additionally, $R^*$ is not based on any single characteristic of the sampling distribution; instead using all the information in the chain. Since our machine learning method, gradient-boosted regression trees, provides uncertainty in predictions, as a byproduct, we obtain uncertainty in $R^*$. The method is straightforward to implement, robust to machine learning hyperparameter choice, and could be a complimentary additional check on MCMC convergence for applied analyses.
\end{abstract}

\section{Introduction}
Markov chain Monte Carlo (MCMC) is the class of exact-approximate methods that has contributed most to applied Bayesian inference in recent years. In particular, MCMC has made Bayesian inference widely available to a wide community of practitioners through the many software packages that use it as an internal inference engine: from Gibbs sampling \cite{geman1984stochastic} that underpins the popular BUGS \cite{lunn2000winbugs} and JAGS \cite{plummer2003jags} libraries, to the more recent algorithms: Hamiltonian Monte Carlo (HMC) \cite{neal2011mcmc} and the No U-Turn Sampler (NUTS) \cite{hoffman2014no}, that Stan \cite{carpenter2017stan} and PyMC3 \cite{salvatier2016probabilistic} implement. MCMC methods are currently the most effective methods for sampling from many classes of posterior distributions encountered in applied work, and it seems unlikely that this trend will change soon.

Its importance in applied scientists' toolkits means it is essential that MCMC is used properly and with adequate care. A cost of automated inference software is that it is increasingly easy to regard MCMC as oracular: giving uncompromised views onto the posterior. Because of this, software packages (Stan in particular \cite{carpenter2017stan} is a great exemplar of this), go to great lengths to communicate to users any issues with sampling. Indeed, in spite of this ease-of-application, many statisticians who develop MCMC methods are less at ease with recommending their use. We repeat here a quote from Chris Holmes to this effect \cite{holmes},

\begin{quote}
	MCMC is most definitely not a panacea and should be used with caution, almost as a last resort. It is just that often we are at the last resort for interesting models.
\end{quote}

The most important determination of whether MCMC has worked is whether the sampling distribution has converged to the posterior \cite{lambert2018Student}. MCMC methods are thus created because of an asymptotic property: that given an infinite number of samples, their sampling distribution approaches the posterior (under general conditions). In the face of only these asymptotic guarantees, it is actually quite miraculous that MCMC samplers \textit{can} often practically converge to the posterior in only a (relatively small) finite number of samples.

The predominant diagnostic method for determining whether practical convergence has occurred relies on the fact that the posterior distribution is the unique stationary distribution for an MCMC sampler. Therefore, it would appear that, if an MCMC sampling distribution stops changing, then convergence has occurred. Unfortunately, anyone who uses MCMC knows that it is full of false dawns: chains can easily become stuck in areas of parameter space and observation over short intervals mean the sampling distribution \textit{appears} converged. Like furious bees trapped in a room of a house \cite{lambertbees}, MCMC samplers may fail to move due to the narrow gaps that join neighbouring areas. With MCMC, absence of evidence of new areas of high posterior density is, time and again, not evidence of their absence.

To combat this curse of hindsight, running multiple, independent, chains, which have been initialised at diverse areas of parameter space is recommended \cite{gelman1992inference}. If the chains appear not to ``mix'' -- a term essentially meaning that it is difficult to resolve an individual chain's path from the mass of paths overlaid on top of one another -- they are yet to converge. This approach makes it less likely that convergence will occur due to chains becoming stuck in an area of parameter space, and running multiple chains is standard recommended practice \cite{lambert2018Student}. The predominant approach to quantitatively measuring this mixing is to compare each chain's sampling distribution to that of the population of chains as a whole: specifically, $\hat{R}$ -- the main convergence statistic used -- compares within-chain variance to that between-chains \cite{gelman2013bayesian}. If these variances are similar, $\hat{R}\approx 1$ and chains are deemed to have mixed. Recently, Stan has adopted more advanced variations on the original $\hat{R}$ formula: for example, splitting individual chains in two to combat poor intra-chain mixing \cite{carpenter2017stan}; and using ranks of parameter samples rather than the raw sample values themselves \cite{vehtari2019rank}. Additionally, there has been more focus on ensuring that the effective sample size (ESS), a measure of sample quality (see, for example, \cite{lambert2018Student}), is sufficient, and accordingly, new measures of this quantity have been proposed \cite{vehtari2019rank} and adopted \cite{carpenter2017stan}. Collectively, these statistics help alert users of MCMC to issues with sampling (that typically echo issues with the model) meaning that all is not hunky dory.

Here, we introduce $R^*$, a new convergence metric. This statistic is built on the intuition that, if the chains are mixed, it should not be possible to discern from a sample the chain that generated it. Rephrased, it should not be possible to predict the chain that \textit{caused} a sample. In this vein, we use a supervised machine learning (ML) approach to measure convergence. Specifically, we train a ML model to classify the chain that caused each observation. By evaluating the performance of the model on a held-out test set, this provides a new convergence metric. To maximise predictive accuracy, ML models naturally exploit differences between the full joint distributions of each chain, which means they are sensitive to variations across all quantiles and parameters -- any of which signal that convergence hasn't occurred. This statistic, unlike its $\hat{R}$ cousins, is univariate: one model provides a single $R^*$ whereas $\hat{R}$ has separate values for each parameter. However, the ML models we use can straightforwardly be interrogated to determine which parameters were most important for generating predictive accuracy. For our machine learning model, we use gradient-boosted regression trees \cite{friedman2001greedy,greenwell2019package} (``GBM''), since these are known to perform well for the types of tabular data that our problem presents \cite{chollet2018}. For the types of problem we test, $R^*$ calculation is of a speed comparable to some of the newer $\hat{R}$ measures calculated and is insensitive to the GBM's hyperparameters and provides a measure of convergence robust to various Markov chain pathologies. In addition, since the outputs from GBMs are class probabilities, we obtain uncertainty measures for $R^*$, which we find provides a useful status of MCMC convergence. $R^*$ can straightforwardly be incorporated into existing software libraries and we argue provides a complementary convergence metric alongside more established measures.

The structure of this paper is as follows: in \S\ref{sec:method}, we describe in detail the method for calculating $R^*$ and its uncertainty; in \S\ref{sec:results}, we examine the performance of $R^*$ across a range of scenarios introduced in \cite{vehtari2019rank}. Code for reproducing the analyses is provided at \url{https://github.com/ben18785/ml-mcmc-convergence}.

%$R^*$ calculation is enabled in Pints inference software \cite{Clerx2019Pints}.

\section{Method}\label{sec:method}
If Markov chains have not mixed, it is possible to determine to which chain a sample belongs from the sample's value. This is possible if there are differences in the sampling distribution for any dimension, $\theta$, in the target distribution (Fig. \ref{fig:marginal}): in this case, if the marginal distributions differ between chains, this information can be used to predict which chain a sample belongs to. It  is also possible to predict the chain that generated a given sample if there are differences in the joint distribution of two (or more) dimensions of the target, even if the marginal distributions are the same (Fig. \ref{fig:joint}).

\begin{figure}[h]
	\centerline{\includegraphics[width=0.6\textwidth]{../output/unmixed_1.pdf}}
	\caption{\textbf{Chain prediction based on marginal distribution of a single parameter.} A shows the path of two chains that have mixed resulting in similar sampling distributions (to right of panel); B shows two chains that have not mixed.}
	\label{fig:marginal}
\end{figure}

\begin{figure}[h]
	\centerline{\includegraphics[width=0.4\textwidth]{../output/unmixed_2.pdf}}
	\caption{\textbf{Chain prediction based on joint distribution of two parameters.} Here, the marginal distributions of each dimensions are similar but the joint distributions differ.}
	\label{fig:joint}
\end{figure}

These two cases, whilst simple, illustrate the basis of our approach. To determine if a set of Markov chains have converged to the same distribution, we train a supervised machine learning (ML) model to classify the chain to which each sample belongs. By evaluating its performance on an independent test set, we delineate whether chains have mixed based on whether classification accuracy is above the ``null'' case, where accuracy is $1/{N}$ where $N$ is the number of chains. By taking the ratio of ML accuracy to this null accuracy, we obtain a statistic that is interpretable in a similar way to $\hat{R}$ \cite{gelman2013bayesian}. In a nod to this established statistic, we call our statistic $R^*$, and, by design, $R^*\approx 1$ signifies convergence. Algorithm X shows how this statistic is constructed.

The ML model we use here is a gradient-boosted regression tree (GBM), which was introduced in \cite{friedman2001greedy}, has been shown to be a highly predictive framework for use in tabular data \cite{chollet2018} like ours. Specifically, we use the GBM implementation in \textbf{\textsf{R}}'s Caret package \cite{kuhn2008building}, which, in turn, uses the ``gbm'' package \cite{greenwell2019package}. The data for each chain has dimensions: $X\in \mathbb{R}^{SK}$, where $S$ is the number of samples taken (here assumed the same for each chain, but this is not a binding constraint) and $K$ is the number of parameters. We split each chain's samples into training and testing tests: here, we use 70\% of samples for training and 30\% for testing. The GBM model we use was found to be rapid to execute training then prediction on the testing set (taking $<1$ second on a desktop computer for models with 1000 samples) and its predictive performance was insensitive to its hyperparameters. In what follows, our hyperparameter settings were: an interaction depth of 3, a shrinkage parameter of 0.1, 10 observations would be the minimum for each node and that 50 trees would be grown (see \url{https://github.com/ben18785/ml-mcmc-convergence} to replicate this functionality).

A benefit of most ML approaches to classification is that they can output class probabilities, opposed to a single predicted class, which we leverage to produce an uncertainty distribution for $R^*$. For each sample, $s$, in our testing set, our GBM outputs a simplex of chain probabilities: $\boldsymbol{p}^{\{s\}}=(p_1^{\{s\}},p_2^{\{s\}},...,p_N^{\{s\}})$, which forms a categorical distribution that can be sampled from to yield a single chain prediction, $c^{\{s\}}$. By comparing this classification to the true classification, $c^s$, we obtain a binary measure, $a^s=\mathbbm{1}(c^{\{s\}}=c^s)$, of whether this prediction was correct. We repeat this sampling process for each sample in the testing set, generating $\boldsymbol{a}=(a^1,a^2,...,a^{N_\text{test}})$, whose average yields a single $R^{*\{i\}}=\bar{a}$ estimate for iteration $i$. We then iterate this process, for $i=1,2,...,I$, producing a set of $(R^{*\{1\}},R^{*\{2\}},...,R^{*\{I\}})$, which collectively represent a distribution for $R^*$. Algorithm Y shows how to calculate this distribution for a given set of MCMC samples.

\section{Results}\label{sec:results}
To illustrate the utility of our approach, we use examples from \cite{vehtari2019rank} with a few additional cases that further illustrate the utility of $R^*$.

\subsection{Heterogeneity in chain variance}\label{sec:heterogeneity}
We generate four Markov chains, where each samples from an autoregressive order 1 (AR1) process of the form,
%
\begin{equation}
X_t = \rho X_{t-1} + \epsilon_t
\end{equation}
%
where $\epsilon_t\stackrel{i.i.d.}{\sim}\mathcal{N}(0, \sigma)$. Three of the chains share the same $\sigma=\bar{\sigma}$, whereas the other chain has $\sigma=1/3\bar{\sigma}$, so that it has $1/3$ of the (unconditional) variance of the others. In each replicate, we simulate 1000 iterations from all four chains and fit a gradient-boosted model to a labelled training set of 2800 randomly-chosen samples, and use it to classify samples according to the chain which generated them in an independent test set comprising the remaining 1200 observations. We perform 1000 replicates and, in each case, we report the ratio of accuracy of the predictions to the null model which assigns observations to chains uniformly at random (i.e. having an accuracy of 25\%).

In Fig. \ref{fig:ar1}A, we show how an example model fit to training data classifies observations by chain according to the sample's value. Unsurprisingly, since the fourth chain has a smaller variance, observations close to zero are likely to be classified as being generated by this chain. In Fig. \ref{fig:ar1}B, we show that the accuracy ratio is well above 1 for all replicates.

%\begin{figure}[h]
%	\centerline{\includegraphics[width=1.0\textwidth]{../output/ar1.pdf}}
%	\caption{\textbf{Autoregressive example.} A shows how the gradient-boosted model's classifications vary according to the sample's value for an example model fit; B shows the ratio of predictive accuracy to the null model accuracy across 1000 replicates; C shows the uncertainty in accuracy ratio for two series described in the text. See the R markdown file in the SOM for hyperparameters and code for fitting the gradient-boosted model.}
%	\label{fig:ar1}
%\end{figure}

Since the gradient-boosted models return a probability simplex for each sample, which indicates the probability it was generated by each chain, we are also able to generate uncertainty in our measure of convergence. For each sample, we randomly sample a chain classification from a multinomial distribution with class probabilities given by the outputs from the machine learning model then check whether this matches the true chain identity. The accuracy is then given by the percentage of samples where the prediction is correct. By repeating this exercise across a number of replicates, we obtain an uncertainty in the accuracy, which we convert to an accuracy ratio as before.

We demonstrate this idea using two datasets: one generated as described above, where one chain (out of four) has a lower variance than the others (we call this the "unconverged data"); and another, where all chains sample from the same distribution (we call this the "converged data"). In Fig. \ref{fig:ar1}C, we show the uncertainty distributions for the accuracy ratio that result from sampling from the underlying fit of a single gradient-boosted model to each dataset. For the unconverged data, the distribution has its bulk of mass away from 1, indicating lack of convergence. For the converged data, the distribution is centred on 1, indicating convergence. 

\subsection{Poor convergence in joint distribution}
Simple AR1 example followed by 250 MVT normal.

\subsection{Infinite variance: Cauchy example}
We next explore how $R^*$ can be used to determine convergence for distributions with infinite variance. Like \cite{vehtari2019rank}, we first use Stan to sample from independent standard Cauchy distributions for each element of a 50-element vector $x$,
%
\begin{equation}
x_j\sim \text{Cauchy}(0, 1),\; \text{for } j=1,...,50,
\end{equation}
%
and monitor convergence of each $x_j$ separately. We call this parameterisation the ``nominal'' version of this model.

In addition, we also use Stan to sample from an ``alternative'' parameterisation of the Cauchy, based on a scale mixture of Gaussians \cite{vehtari2019rank},
%
\begin{align}
a_j \sim  \N(0,1), \qquad
b_j \sim  \text{Gamma}(0.5, 0.5), \qquad
x_j =  a_j/\sqrt{b_j}.
\end{align}
%
The distribution of the $x$ vector is the same under both parameterisations, although the thin-tailed $(a,b)$ vectors define a higher dimensional posterior that improves sampling efficiency.

In Fig. \ref{fig:cauchy}A, we show the $R^*$ distribution under both parameterisations. As shown in \cite{vehtari2019rank}, the nominal parameterisation results in poor sampling efficiency due to its long tails, meaning that, after 2000 MCMC iterations, the samples still contain information about the chain identity, and, accordingly, the $R^*$ distribution is shifted rightwards from $R^*=1$. The alternative parameterisation fares better and the $R^*$ distribution is nearer $R^*=1$. Interesting, however, in contrast to the measures presented in \cite{vehtari2019rank}, the $R^*$ distribution for the alternative parameterisation has a mean above 1, indicating that more MCMC iterations are needed: in Fig. \ref{fig:cauchy}B, we show the result for running each Stan model for ten times as long (and thinning by a factor of 5). In this figure, the alternative parameterisation now has an $R^*$ distribution centered on $R^*=1$ and, hence, we are more confident that convergence has been reached. Despite the added iterations, the $R^*$ distribution from the nominal model remains stubbornly away from 1.

%\begin{figure}[h]
%	\centerline{\includegraphics[width=1.0\textwidth]{../output/cauchy.pdf}}
%	\caption{\textbf{Cauchy example.} A shows 1000 samples from the $R^*$ distribution generated under two model parameterisations. See the R markdown file in the SOM for hyperparameters and code for fitting the gradient-boosted model.}
%	\label{fig:cauchy}
%\end{figure}

\subsection{Hierarchical model: Eight schools}
In this example, we examine a simple classic example used to highlight difficulties in performing sampling for hierarchical models: referred to as the "Eight schools" model (see Section 5.5 in \cite{gelman2013bayesian}), which aimed to determine the effects of coaching on SAT scores in eight schools. 

The model can be parameterised two ways, as described in \cite{vehtari2019rank}. The simplest way is referred to as the "centered" parameterisation and exactly mirrors the underlying statistical model,
%
\begin{align*}
\theta_j &\sim \N(\mu, \tau) \\
y_j &\sim \N(\theta_j, \sigma_j).
\end{align*}
%
The non-centered parameterisation recodes this model in a way which does not affect the joint distribution of $(\tilde{\theta}, \mu, \tau, \sigma)$ but makes it easier to sample from it, by introducing auxillary variables. This can be written as,
%
\begin{align*}
\tilde{\theta}_j &\sim \N(0, 1) \\
\theta_j &= \mu + \tau \tilde{\theta}_j \\
y_j &\sim \N(\theta_j, \sigma_j).
\end{align*}
%
In both cases, $\theta_j$ are the treatment effects in the eight schools, and $\mu, \tau$ represent the population mean and standard deviation 
of the distribution of these effects. In the centered parameterization, the $\theta$ are parameters, whereas in the non-centered parameterization, the $\tilde{\theta}$ are parameters and $\theta$ is a derived quantity.

We first used Stan \cite{carpenter2017stan} to sample from the centered model using 4 chains. Like \cite{vehtari2019rank}, we use settings that reduce the chance of divergent iterations for the NUTS algorithm \cite{hoffman2014no}, meaning that the resultant sampling distribution is likely to be biased. We also used Stan with the same algorithm settings to sample from the non-centered model.

To see how $R^*$ performed on this example, we first split each of the (post-warm-up) chains in two, as is done by default in Stan \cite{carpenter2017stan} and in \cite{vehtari2019rank}, resulting in 500 iterations across 8 chains. Next, we trained the gradient-boosted model on a training set comprising 2800 samples, and used it to classify the causative chain for 1200 independent test samples. Following the same approach as in \S\ref{sec:heterogeneity}, we generated uncertainty in $R^*$ for both the centered and non-centered models. The resultant distributions for $R^*$ are shown in Fig.\ref{fig:eight_schools}A. In this plot, it is clear that whereas the centered model shows signs of convergence, the non-centered model does not: intuitively, the chains have not sufficiently mixed with themselves nor the others meaning that the causative chain can be predicted with reasonable accuracy from the sample location.

In gradient-boosted tree models (GBMs), it is possible to calculate variable importance (see, for example, \cite{friedman2001greedy} and \cite{greenwell2019package}), and this allows us to determine which variables were mostly responsible for predictive power. For GBM fitted to the centered model, the most important variable was $\tau$, followed by Stan's $lp$ variable (we also include this in our training and testing data), followed by $\mu$ and $\theta_2$. Interestingly, these were slightly differently ordered according to Stan's $\hat{R}$, with $lp$ having the highest value ($\hat R = 1.06$), followed by $\tau$ ($\hat R = 1.02$), then a host of variables with ($\hat R = 1.01$).

In addition, to illustrate the power of $R^*$, we also repeat the analysis but, this time, do not split the chains in two. The results are shown in Fig.\ref{fig:eight_schools}B. In this case, because the unsplit chains do not mix with themselves, it is harder to accurately predict the chain that generated each sample, meaning that the centered model $R^*$ values are shifted leftwards. Despite this, however, the distribution for $R^*$ still does not strongly overlap with $R^*=1$, indicating that the model has not converged.

%\begin{figure}[h]
%	\centerline{\includegraphics[width=1.0\textwidth]{../output/eight_schools.pdf}}
%	\caption{\textbf{Eight schools example.} A shows samples from the $R^*$ distribution when splitting chains; B shows the same but using the 4 original chains. In both cases, the plots show 1000 samples. See the R markdown file in the SOM for hyperparameters and code for fitting the gradient-boosted model.}
%	\label{fig:eight_schools}
%\end{figure}

\section{Discussion}
Add in index variable into set of predictors.
Relative insensitivity of GBM to settings (in all examples we used the same hyperparameters)



	
\bibliographystyle{unsrt}
\bibliography{bibliography} 
	
\end{document}
